{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619519a8",
   "metadata": {},
   "source": [
    "# Initial Commit\n",
    "First py notebook for full run through of data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    !pip install transformers\n",
    "    !pip install bertviz\n",
    "    !pip install tensorflow\n",
    "    !pip install seaborn\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create generator for gpt2 pipeline {display-mode: \"form\"}\n",
    "\n",
    "import os\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "\n",
    "training_text_filename = \"method-generation.txt\"\n",
    "training_text_file_location = os.path.join(os.getcwd(), \"Train\", \"method-generation.txt\")\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2', tokenizer='gpt2', output_attentions=True)\n",
    "set_seed(42)\n",
    "\n",
    "with open(training_text_file_location) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate new words, tokenize said words {display-mode: \"form\"}\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "generated_text = generator(data, max_new_tokens=500, num_return_sequences=1)\n",
    "\n",
    "for a in range(len(generated_text)):\n",
    "    generated_text[a] = generated_text[a]['generated_text']\n",
    "    print(generated_text[a])\n",
    "\n",
    "new_words = generated_text[0][len(data):]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "tokens = tokenizer(new_words, return_tensors='pt')\n",
    "tokens_out = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66432a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Visualize frequency count of output {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "counts = Counter(tokens_out)\n",
    "\n",
    "token_freq = pd.DataFrame(counts.items(),columns=['token','frequency']).sort_values(by='frequency',ascending=False)\n",
    "\n",
    "token_freq = token_freq.head(20)\n",
    "\n",
    "sns.barplot(x='frequency',y='token',data=token_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Prepare by running model, getting attention and input token ids {display-mode: \"form\"}\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "model = AutoModel.from_pretrained(\"gpt2\", output_attentions=True)\n",
    "\n",
    "inputs = tokenizer(data[120:170], return_tensors='pt')\n",
    "print(inputs)\n",
    "outputs = model(**inputs)\n",
    "attention = outputs.attentions  # Output includes attention weights when output_attentions=True\n",
    "\n",
    "tokens_input = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "print(tokens_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Demo BertViz head view and model view {display-mode: \"form\"}\n",
    "\n",
    "from bertviz import head_view, model_view\n",
    "\n",
    "head_view(attention, tokens_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
