{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiNxsd4_q9wq"
   },
   "source": [
    "### What-If Tool Demo toxicity text model comparison\n",
    "\n",
    "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) to compare two text models that determine sentence toxicity, one of which has had some debiasing performed during training.\n",
    "\n",
    "This notebook loads two pretrained toxicity models from [ConversationAI](https://github.com/conversationai/unintended-ml-bias-analysis) and compares them on the [wikipedia comments dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973).\n",
    "\n",
    "This notebook also shows how the What-If Tool can be used on non-TensorFlow models. In this case, these models are keras models that do not use tensorflow Examples as an input format. These models can be analyzed in the What-If Tool by supplying a custom prediction function to WitWidget.\n",
    "\n",
    "It also shows use of a user-provided custom distance function (for counterfactual analysis and datapoint similarity visualizations). The [tf.Hub Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/2) is used to compute the similarity of the input text comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qqB2tjOMETmr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: witwidget in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (1.8.1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (8.0.2)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (2.64.0)\n",
      "Requirement already satisfied: oauth2client>=4.1.3 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (4.1.3)\n",
      "Requirement already satisfied: tensorflow>=1.12.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (1.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from witwidget) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->witwidget) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->witwidget) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->witwidget) (2.10.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->witwidget) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->witwidget) (2.12.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipywidgets>=7.0.0->witwidget) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipywidgets>=7.0.0->witwidget) (6.15.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipywidgets>=7.0.0->witwidget) (3.0.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipywidgets>=7.0.0->witwidget) (8.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipywidgets>=7.0.0->witwidget) (4.0.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from oauth2client>=4.1.3->witwidget) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from oauth2client>=4.1.3->witwidget) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from oauth2client>=4.1.3->witwidget) (4.9)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (20210226132247)\n",
      "Requirement already satisfied: packaging in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (2.10.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (0.27.0)\n",
      "Requirement already satisfied: setuptools in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (63.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (1.49.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (2.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (1.23.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorflow>=1.12.1->witwidget) (3.19.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=1.12.1->witwidget) (0.35.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (1.56.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (2.28.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.7.8->witwidget) (5.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.7.8->witwidget) (3.0.9)\n",
      "Requirement already satisfied: nest-asyncio in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (7.3.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (0.1.6)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (1.5.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (23.2.0)\n",
      "Requirement already satisfied: appnope in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (0.1.2)\n",
      "Requirement already satisfied: psutil in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (5.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (2.11.2)\n",
      "Requirement already satisfied: decorator in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (3.0.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (2.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (4.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->witwidget) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.2.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.7.8->witwidget) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (2.1.1)\n",
      "Requirement already satisfied: asttokens in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (2.0.5)\n",
      "Requirement already satisfied: executing in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->witwidget) (0.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/dtran/opt/anaconda3/envs/wit-env/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=1.12.1->witwidget) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "#@title Install the What-If Tool widget if running in colab {display-mode: \"form\"}\n",
    "\n",
    "# If running in colab then pip install, otherwise no need.\n",
    "try:\n",
    "    import google.colab\n",
    "    !pip install --upgrade tensorflow>=2.0.0 witwidget # type: ignore\n",
    "except Exception:\n",
    "    !pip install witwidget\n",
    "    !jupyter nbextension install --py --symlink --sys-prefix witwidget\n",
    "    !jupyter nbextension enable --py --sys-prefix witwidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBOHfrOP7Iy5",
    "outputId": "b30ff7c4-2e33-429f-df2b-848c6a067676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 59.5M  100 59.5M    0     0  18.9M      0  0:00:03  0:00:03 --:--:-- 18.9M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   227  100   227    0     0   1759      0 --:--:-- --:--:-- --:--:--  1759\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10.7M  100 10.7M    0     0  13.2M      0 --:--:-- --:--:-- --:--:-- 13.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 61.6M  100 61.6M    0     0  20.1M      0  0:00:03  0:00:03 --:--:-- 20.1M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   229  100   229    0     0   1817      0 --:--:-- --:--:-- --:--:--  1817\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11.1M  100 11.1M    0     0  15.5M      0 --:--:-- --:--:-- --:--:-- 15.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13.7M  100 13.7M    0     0  12.0M      0  0:00:01  0:00:01 --:--:-- 12.0M\n"
     ]
    }
   ],
   "source": [
    "#@title Download the pretrained keras model files\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_wiki_tox_v3_model.h5 -o ./cnn_wiki_tox_v3_model.h5\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_wiki_tox_v3_hparams.h5 -o ./cnn_wiki_tox_v3_hparams.h5\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_wiki_tox_v3_tokenizer.pkl -o ./cnn_wiki_tox_v3_tokenizer.pkl\n",
    "\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_debias_tox_v3_model.h5 -o ./cnn_debias_tox_v3_model.h5\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_debias_tox_v3_hparams.h5 -o ./cnn_debias_tox_v3_hparams.h5\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/cnn_debias_tox_v3_tokenizer.pkl -o ./cnn_debias_tox_v3_tokenizer.pkl\n",
    "\n",
    "!curl -L https://storage.googleapis.com/what-if-tool-resources/computefest2019/wiki_test.csv -o ./wiki_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zZR3i6UZlZ96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 20:14:27.044433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#@title Load the keras models\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pkl\n",
    "\n",
    "def pkl_load(f):\n",
    "  return pkl.load(f) if sys.version_info < (3, 0) else pkl.load(\n",
    "    f, encoding='latin1')\n",
    "\n",
    "model1 = tf.keras.models.load_model('cnn_wiki_tox_v3_model.h5')\n",
    "with open('cnn_wiki_tox_v3_tokenizer.pkl', 'rb') as f:\n",
    "  tokenizer1 = pkl_load(f)\n",
    "tokenizer1.oov_token = None # quick fix for version issues\n",
    "\n",
    "model2 = tf.keras.models.load_model('cnn_debias_tox_v3_model.h5')\n",
    "with open('cnn_debias_tox_v3_tokenizer.pkl', 'rb') as f:\n",
    "  tokenizer2 = pkl_load(f)\n",
    "tokenizer2.oov_token = None # quick fix for version issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nStoYhqT80WH"
   },
   "outputs": [],
   "source": [
    "#@title Define custom prediction functions so that WIT infers using keras models\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set up model helper functions:\n",
    "PADDING_LEN = 250\n",
    "\n",
    "# Convert list of tf.Examples to list of comment strings.\n",
    "def examples_to_strings(examples):\n",
    "  texts = [ex.features.feature['comment'].bytes_list.value[0] for ex in examples]\n",
    "  if sys.version_info >= (3, 0):\n",
    "    texts = [t.decode('utf-8') for t in texts]\n",
    "  return texts\n",
    "\n",
    "# Get raw string out of tf.Example and prepare it for keras model input\n",
    "def examples_to_model_in(examples, tokenizer):\n",
    "  texts = examples_to_strings(examples)\n",
    "  # Tokenize string into fixed length sequence of integer based on tokenizer \n",
    "  # and model padding\n",
    "  text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "  model_ins = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      text_sequences, maxlen=PADDING_LEN)\n",
    "  return model_ins\n",
    "\n",
    "# WIT predict functions:\n",
    "def custom_predict_1(examples_to_infer):\n",
    "  model_ins = examples_to_model_in(examples_to_infer, tokenizer1)\n",
    "  preds = model1.predict(model_ins)\n",
    "  return preds\n",
    "\n",
    "def custom_predict_2(examples_to_infer):\n",
    "  model_ins = examples_to_model_in(examples_to_infer, tokenizer2)\n",
    "  preds = model2.predict(model_ins)\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NXaUORW0DVhg"
   },
   "outputs": [],
   "source": [
    "#@title Define helper functions for dataset conversion from csv to tf.Examples\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "  examples = []\n",
    "  if columns == None:\n",
    "    columns = df.columns.values.tolist()\n",
    "  for index, row in df.iterrows():\n",
    "    example = tf.train.Example()\n",
    "    for col in columns:\n",
    "      if df[col].dtype is np.dtype(np.int64):\n",
    "        example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "      elif df[col].dtype is np.dtype(np.float64):\n",
    "        example.features.feature[col].float_list.value.append(row[col])\n",
    "      elif row[col] == row[col]:\n",
    "        example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "    examples.append(example)\n",
    "  return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nu398ARdeuxe",
    "outputId": "ba0f4582-356d-4511-a936-a10fc09886f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\e'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\.'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\A'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\,'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\_'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\Â'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\Ë'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\)'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\p'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\S'\n",
      "  c = c.decode('unicode_escape')\n",
      "/var/folders/11/znbx5sdn46zb_k31yz8gfrd00000gn/T/ipykernel_14484/3034194029.py:23: DeprecationWarning: invalid escape sequence '\\æ'\n",
      "  c = c.decode('unicode_escape')\n"
     ]
    }
   ],
   "source": [
    "#@title Read the dataset from CSV and process it for model {display-mode: \"form\"}\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the CSV containing the dataset to train on.\n",
    "csv_path = 'wiki_test.csv'\n",
    "\n",
    "# Set the column names for the columns in the CSV. If the CSV's first line is a header line containing\n",
    "# the column names, then set this to None.\n",
    "csv_columns = None\n",
    "\n",
    "# Read the dataset from the provided CSV and print out information about it.\n",
    "df = pd.read_csv(csv_path, names=csv_columns, skipinitialspace=True)\n",
    "df = df[['is_toxic', 'comment']]\n",
    "\n",
    "# Remove non ascii characters\n",
    "comments = df['comment'].values\n",
    "proc_comments = []\n",
    "comment_lengths = []\n",
    "for c in comments:\n",
    "  try:\n",
    "    if sys.version_info >= (3, 0):\n",
    "      c = bytes(c, 'utf-8')\n",
    "    c = c.decode('unicode_escape')\n",
    "    if sys.version_info < (3, 0):\n",
    "      c = c.encode('ascii', 'ignore')\n",
    "    proc_comment = c.strip()\n",
    "  except:\n",
    "    proc_comment = ''\n",
    "  proc_comments.append(proc_comment)\n",
    "  comment_lengths.append(len(proc_comment.split()))\n",
    "\n",
    "df = df.assign(comment=proc_comments)\n",
    "df['comment length'] = comment_lengths\n",
    "\n",
    "label_column = 'is_toxic'\n",
    "make_label_column_numeric(df, label_column, lambda val: val)\n",
    "\n",
    "examples = df_to_examples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "tr7Eg9Ni8joJ",
    "outputId": "8c315760-1c8a-44c5-fc4a-4628f008805d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>comment length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31866.000000</td>\n",
       "      <td>31866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095651</td>\n",
       "      <td>68.168644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294116</td>\n",
       "      <td>99.563199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1403.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           is_toxic  comment length\n",
       "count  31866.000000    31866.000000\n",
       "mean       0.095651       68.168644\n",
       "std        0.294116       99.563199\n",
       "min        0.000000        0.000000\n",
       "25%        0.000000       17.000000\n",
       "50%        0.000000       37.000000\n",
       "75%        0.000000       76.000000\n",
       "max        1.000000     1403.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Display descriptive stats of data {display-mode: \"form\"}\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY0uFrew9Osr",
    "outputId": "4bfb09c4-ab56-4565-99b3-3dfa1c1221d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Elected or Electoral? JHK\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 4\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Please relate the ozone hole to increases in cancer, and provide figures. Otherwise, this article will be biased toward the environmentalist anti-CFC point of view instead of being neutral. Ed Poor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 31\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"`    I\\'m not sure if it\\'s properly called ``fifth tuning`` or ``perfect fifth tuning`` or what, but it does exist. The octave is slightly sharper than twice the frequency, but according to the book it sounds better that way because the first overtone of a piano is itself sharp. I don\\'t have a piano, so I\\'ve never tried it; besides, the second overtone is even sharper than the first (stiff strings do that). -`\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 74\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Thanks on the info on how to move a page. re:   The Walt Disney Company. [User:Christopher Mahan|Chris Mahan] 20020906\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 19\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"`  : I should do that too, I agree, but I\\'ve also encountered (not today) pages with similar contents that had nothing to do with 9/11. In my ``cleaning frenzy``, I just forget to check. `\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 36\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"`Well, I am not trying to pick a fight ) but I have NPOV issues with this article.  It reads  at the moment  like a celebration of scientific progress.  I have two problems: first, it moves too easily from science as a generic activity all people engage in, to science as a specifically Western project.  Second, although there has been progress in science in that there is some accumulation of knowledge, the history of science is rather more complicated than that.    One way to deal with this (if others find my criticisms valid) is to distinguish in the article between what we know about changes in scientific method and knowledge (from Aristotle to Bacon to Comte to Popper; from Aristotle to Darwin to Mendel to Mayr; from Aristotle to Newton to Einstein and Planck; etc, on the one hand, and various discussions over how to study and conceive of the history of science (i.e. issues in historiography and the sociology of science), on the other.  For example, I think everyone agrees that Aristotle, Newton, Einstein and Planck are real people who lived at different periods of time and made different claims about the world  but I think different people have vastly different ways of telling the story that connects these people and their claims.  I\\'d hope a good article on ``the history of science`` would inform me of these issues, and provide me with the different ways of understanding the movement from one period in science to another.    I am no expert on this but I really hope someone who feels very confident of their grasp of, say, Thomas Kuhn and Bruno Latour, could reorganize and develop this article in a way that takes their claims about science seriously, as well as the claims of those with opposing views.    I am glad Ed has begun this article, it can be really important and it is a needed contribution.   SR  `\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 320\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"` :Thanks, but I don\\'t have that link. I\\'m using the layout with a blue bar across the top (talk and uneditable pages are yellow, links are color coded and so on). I\\'ll try logging out and seeing if it appears. Also, on naming conventions, did I make a mistake? To my knowledge the ``programming language`` suffix for languages has been a long-agreed-apon standard. I was just moving some pages to adhere to that. Sorry about not using the ``move this page`` feature though. I\\'ll look again and see if it is there and I just didn\\'t see it. For the record though, most of the articles I moved didn\\'t have a history (I think maybe 2 or 3 of them did, but the others were only auto-imported or ``convertion script`` items without a history beyond that. Again, sorry if I messed things up. I\\'d be happy to fix anything I break if I can figure out how. Also, I should probably add redirects in those blank articles.  22:05 Oct 20, 2002 (UTC)`\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 173\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"whats so pro-israeli propagandish about arabs claiming the us is to blame for their economic conditions?  02:20 Nov 16, 2002 (UTC)\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 21\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Oh, I\\'m sure I could find a copy around somewhere... I just wanted to be able to link to it from the page.\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 23\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", features {\n",
      "  feature {\n",
      "    key: \"comment\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Is something like Managing_Urban_America going to be a problem?  16:52 Dec 20, 2002 (UTC)\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"comment length\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 14\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"is_toxic\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#@title Display format  {display-mode: \"form\"}\n",
    "print(examples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lVaMyc45HWwD"
   },
   "outputs": [],
   "source": [
    "#@title Define a custom distance function for comparing datapoints (uses tf.Hub) {display-mode: \"form\"}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# For this use-case, we set distance between datapoints to be cosine distance\n",
    "# between unit-normalized embeddings of each datapoint from the tf.Hub\n",
    "# Universal Sentence Encoder.\n",
    "def universal_sentence_encoder_distance(input_example, examples_to_compare, _):\n",
    "  # Extract comment strings\n",
    "  input_sentence = examples_to_strings([input_example])[0]\n",
    "  sentences = examples_to_strings(examples_to_compare)\n",
    "\n",
    "  # Normalize all embeddings for cosine distance operation\n",
    "  input_emb = tf.squeeze(tf.nn.l2_normalize(embed([input_sentence]), axis=1))\n",
    "  sentences_emb = tf.nn.l2_normalize(embed(sentences), axis=1)\n",
    "\n",
    "  # Tile the input example for easy comparison to all examples\n",
    "  multiply = tf.constant([len(examples_to_compare)])\n",
    "  input_matrix = tf.reshape(tf.tile(input_emb, multiply),\n",
    "                            [multiply[0], tf.shape(input_emb)[0]])\n",
    "  \n",
    "  # Compute cosine distance from input example to all examples.\n",
    "  cosine_distance = tf.keras.losses.CosineSimilarity(\n",
    "      axis=1, reduction=tf.losses.Reduction.NONE)\n",
    "  distances = cosine_distance(sentences_emb, input_matrix)\n",
    "  results = tf.squeeze(distances)\n",
    "  return results.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737,
     "resources": {
      "http://localhost:8080/data/plugins_listing": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/d-6IYplOFocCacKzxwXSOJBw1xU1rKptJj_0jans920.woff2": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      },
      "http://localhost:8080/font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "UwiWGrLlSWGh",
    "outputId": "cf4d58e8-dc8c-4d1d-c553-665d43864e7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Invoke What-If Tool for the data and two models (Note that this step may take a while due to prediction speed of the toxicity model){display-mode: \"form\"}\n",
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
    "num_datapoints = 1000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 720  #@param {type: \"number\"}\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[:num_datapoints]).set_custom_predict_fn(\n",
    "  custom_predict_1).set_compare_custom_predict_fn(custom_predict_2).set_custom_distance_fn(\n",
    "      universal_sentence_encoder_distance)\n",
    "\n",
    "wv = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a01bbc265f4375ac1cb51c1e4b9855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferenc…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca5a367b871d3d9114338070f6c9e6601522ba0f3c2ff4e97677bd75c8f76b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
