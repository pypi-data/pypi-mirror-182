{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from profit.sur.backend.gp import (kern_sqexp, gp_nll, gp_matrix, \n",
    "                                  gp_matrix_train, gp_optimize)\n",
    "from profit.sur.backend.gpytorch import GPyTorchSurrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y, a, b):\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "def f(r, u, v):\n",
    "    return rosenbrock((r - 0.5) + u - 5, 1 + 3 * (v - 0.6), a=1, b=3)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.linspace(4.7, 5.3, 40)\n",
    "v = np.linspace(0.55, 0.6, 40)\n",
    "y = np.fromiter((f(0.25, uk, vk) for vk in v for uk in u), float)\n",
    "[U,V] = np.meshgrid(u, v)\n",
    "Y = y.reshape(U.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.contour(U,V,Y)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Generate training data\n",
    "utrain = u[::5]\n",
    "vtrain = v[::5]\n",
    "xtrain = np.array([[uk, vk] for vk in vtrain for uk in utrain])\n",
    "ytrain = np.fromiter((f(0.25, uk, vk) for vk in vtrain for uk in utrain), float)\n",
    "ntrain = len(ytrain)\n",
    "\n",
    "#sigma_meas = 1e-10\n",
    "#sigma_meas = 1e-5\n",
    "sigma_meas = 1e-2*(np.max(ytrain)-np.min(ytrain))\n",
    "\n",
    "#%% Plot and optimize hyperparameters\n",
    "\n",
    "# hypaplot = np.linspace(0.1,2,100)\n",
    "# nlls = np.fromiter(\n",
    "#         (gp_nll(hyp, xtrain, ytrain, sigma_meas) for hyp in hypaplot), float)\n",
    "# plt.figure()\n",
    "# plt.title('Negative log likelihood in kernel hyperparameters')\n",
    "# plt.plot(hypaplot, nlls)\n",
    "# #plt.ylim([-80,-60])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sur = GPyTorchSurrogate()\n",
    "sur.train(xtrain, ytrain)\n",
    "\n",
    "xtest = np.array([[uk, vtrain[1]] for uk in u])\n",
    "ytest = np.fromiter((f(0.25, xk[0], xk[1]) for xk in xtest), float)\n",
    "ftest = sur.predict(xtest)\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(xtrain[8:16,0], ytrain[8:16], sigma_meas*1.96, capsize=2, fmt='.')\n",
    "plt.plot(xtest[:,0], ytest)\n",
    "plt.plot(xtest[:,0], ftest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sur.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ytrain-np.mean(ytrain))/np.std(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
