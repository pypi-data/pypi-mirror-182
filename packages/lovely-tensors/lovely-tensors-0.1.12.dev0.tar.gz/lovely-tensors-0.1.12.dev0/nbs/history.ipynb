{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“œ IPython's history obsession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what happens when a variable falls of the end of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |eval: false\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |eval: false\n",
    "t = torch.tensor(10, device=\"cuda\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |eval: false\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |eval: false\n",
    "del t\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, I allocated a tensor in CUDA memory and displayed it as the cell output, then deleted it.\\\n",
    "I did not use Lovely Tensors, just plain PyTorch.\\\n",
    "Why is the CUDA memory not freed? Is there still a reference to the tensor somewhere?\n",
    "\n",
    "> Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " '_',\n",
       " '_2',\n",
       " '_3',\n",
       " '_4',\n",
       " '_5',\n",
       " '_VSCode_matplotLib_FigureFormats',\n",
       " '__',\n",
       " '___']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir()[:10] # Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the _<n> variables?\\\n",
    "They are created by IPython and every cell output you run is saved:\\\n",
    "[https://ipython.readthedocs.io/en/stable/interactive/reference.html#output-caching-system](https://ipython.readthedocs.io/en/stable/interactive/reference.html#output-caching-system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# |eval: false\n",
    "print(_3) # Here is my tensor from cell 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is not the behavior you want, you can disable it by adding\n",
    "\n",
    "`%config ZMQInteractiveShell.cache_size = 0`\n",
    "\n",
    "at the begining of your notebook, but I think this only works in plain Jupyter and not Jupyter in vscode.\n",
    "\n",
    "Alternatively, find your pytorch config file (for me it's `~/.ipython/profile_default/ipython_kernel_config.py`)\\\n",
    " and set ZMQInteractiveShell.cache_size to 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
