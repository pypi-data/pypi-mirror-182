# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_data.ipynb.

# %% auto 0
__all__ = ['Loader', 'FeaturesRemoval', 'CleanV4DataProxy', 'PredictionsExporter', 'KeysConfig', 'PredictionsUploader']

# %% ../nbs/02_data.ipynb 4
import logging
import json
import os
import pandas as pd
from pathlib import Path

from numerapi import NumerAPI

# %% ../nbs/02_data.ipynb 5
class Loader():
    def __init__(self, data_path: Path):
        self.data_path = data_path

    def feature_metadata(self):
        with open(os.path.join(self.data_path, 'features.json'), "r") as f:
            feature_metadata = json.load(f)
        return feature_metadata

    def training_data(self, read_columns=None):
        return pd.read_parquet(f'{self.data_path}/train.parquet',
                               columns=read_columns)

    def live_data(self, current_round, read_columns=None):
        return pd.read_parquet(f'{self.data_path}/live_{current_round}.parquet', columns=read_columns)

    def validation_data(self, current_round, read_columns=None):
        return pd.read_parquet(f'{self.data_path}/validation_{current_round}.parquet', columns=read_columns)

    def example_preds(self, current_round=None):
        return pd.read_parquet(f'{self.data_path}/live_example_preds_{current_round}.parquet')

    def validation_example_preds(self, current_round=None):
        return pd.read_parquet(
            f'{self.data_path}/validation_example_preds_{current_round}.parquet')

# %% ../nbs/02_data.ipynb 6
from pandas import DataFrame
class FeaturesRemoval():
    def drop(data_frame: DataFrame, features: [], inplace: bool):
        return data_frame.drop(columns=features, inplace=inplace) 


# %% ../nbs/02_data.ipynb 7
class CleanV4DataProxy():
    def __init__():
        pass

# %% ../nbs/02_data.ipynb 9
class PredictionsExporter:
    def __init__(self, data_path: Path):
        self.data_path = data_path
        
    def exportLivePredictions(self, model_name: str, current_round: int, dataFrame: pd.DataFrame):
        try:
            Path(
                f'{self.data_path}/predictions/{model_name}').mkdir(exist_ok=True, parents=True)
        except Exception as ex:
            pass

        dataFrame.to_csv(
            f'{self.data_path}/predictions/{model_name}/live_predictions_{current_round}.csv')

    def exportValidationPredictions(self, model_name: str, current_round: int, dataFrame: pd.DataFrame):
        try:
            Path(
                f'{self.data_path}/predictions/{model_name}').mkdir(exist_ok=True, parents=True)
        except Exception as ex:
            pass
        dataFrame.to_csv(
            f'{self.data_path}/predictions/{model_name}/validation_predictions_{current_round}.csv')



# %% ../nbs/02_data.ipynb 10
class KeysConfig():
    def keys(self, data_path: Path):
        with open(os.path.join(f'{data_path}/.numerai/', '.keys'), "r") as f:
            keys = json.load(f)
        return (keys['numerai']['NUMERAI_PUBLIC_ID'], keys['numerai']['NUMERAI_SECRET_KEY'])


# %% ../nbs/02_data.ipynb 11
class PredictionsUploader():
    def __init__(self, public_id: str, secret_key: str, data_path: Path):
        self.public_id = public_id
        self.secret_key = secret_key
        self.data_path = data_path

    def uploadPredictions(self, model_name: str, current_round: int):
        napi = NumerAPI(self.public_id, self.secret_key)

        model_id = napi.get_models()[model_name]
        napi.upload_predictions(
            f'{self.data_path}/predictions/{model_name}/live_predictions_{current_round}.csv', model_id=model_id)

        # check submission status
        napi.submission_status(model_id)
    
    def uploadValidation(self, model_name: str, current_round: int):
        napi = NumerAPI(self.public_id, self.secret_key)

        model_id = napi.get_models()[model_name]
        napi.upload_diagnostics(
            f'{self.data_path}/predictions/{model_name}/validation_predictions_{current_round}.csv', model_id=model_id
        )

        # check submission status
        napi.submission_status(model_id)

