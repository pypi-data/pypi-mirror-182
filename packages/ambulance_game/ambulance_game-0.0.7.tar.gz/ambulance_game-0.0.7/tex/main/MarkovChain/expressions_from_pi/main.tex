\subsection{Expressions derived from \( \pi \):}
One may easily derive the average number of individuals that are at any given state 
using \( pi \). 
The average number of individuals in state \( i \) can be calculated by multiplying 
the number of individuals that are present in state \( i \) with the probability 
of being at that particular state (i.e \(\pi_i (u_i + v_i)\)). 
Using this logic it is possible to calculate any performance measures that are related 
to the mean number of individuals in the system.


Average number of people in the system: 
\begin{equation}
    L = \sum_{i=1}^{|\pi|} \pi_i (u_i + v_i)
\end{equation} 

Average number of people in the service centre: 
\begin{equation}
    L_H = \sum_{i=1}^{|\pi|} \pi_i v_i
\end{equation}

Average number of people in the buffer centre:
\begin{equation}
    L_A = \sum_{i=1}^{|\pi|} \pi_i u_i
\end{equation}

Consequently getting the performance measures that are related to the duration of 
time is not as straightforward. 
Such performance measures are the mean waiting time in the system and the mean time 
blocked in the system. 
Under the scope of this study three approaches have been considered to calculate these 
performance measures; a direct approach, a recursive algorithm and consequently a
closed-form formula.

The research question that needs to be answered here is: ``When a class 1/2 
individuals enters the system, what is the expected time that they will have to 
wait?''. 
In order to formulate the answer to that question one needs to consider all possible 
scenarios of what state the system can be in when an individual arrives. 
Furthermore, different formulas arises for class 1 individuals 
and a different one for class 2 individuals.

\subsection{Mean waiting time} 
\subsubsection{Recursive formula for mean waiting time of class 1 individuals}
\label{sec:recursive-waiting-time-others}

To calculate the mean waiting time of class 1 individuals one must first identify 
the set of states \((u, v)\) that will imply that a wait will occur. 
For this particular Markov chain, this points to all states that satisfy \(v > C\) 
i.e. all states where the number of individuals in the service centre exceed the 
number of servers. 
The set of such states is defined as \textit{waiting states} and can be denoted 
as a subset of all the states, where:

\begin{equation} \label{eq:waiting_states}
    S_w = \{(u, v) \in S \; | \; v > C \}    
\end{equation}

Additionally, there are certain states in the model where arrivals cannot occur. 
A class 1 individual cannot arrive whenever the model is at any state 
\((u, N)\) 
for all \(u\) where \(N\) is the system capacity. 
Therefore the set of all such states that an arrival may occur are defined as 
\textit{accepting states} and are denoted as:

\begin{equation}\label{eq:accepting_states_class_1}
    S_A^{(1)} = \{(u, v) \in S \; | \; v < N \}
\end{equation}



Moreover, another element that needs to be considered is the expected waiting time 
in each state \( c(u,v) \), otherwise known as sojourn time \cite{Raghunandanan}. 
In order to do so a variation of the Markov model has to be considered where when 
the individual arrives at any of the states of the model no more arrivals can 
occur after that. 


\begin{figure}[h]
    \centering
    \begin{tikzpicture}[-, node distance = 1.4cm, auto]

        \tikzmath{
            let \minsz = 1.8cm;
        }

        \node[draw=none, minimum size=\minsz] (one) {};
        \node[state, minimum size=\minsz, right=of one] (two) {(0,T-1)};
        \node[state, minimum size=\minsz, right=of two] (three) {(0,T)};
        \node[state, minimum size=\minsz, right=of three] (four) {(0,T+1)};
        \node[draw=none, minimum size=\minsz, right=of four] (five) {};

        \node[state, draw=red, line width=0.5mm, minimum size=\minsz, 
        below=of three] (three_one) {(1,T)};
        \node[state, draw=red, line width=0.5mm, minimum size=\minsz, 
        below=of three_one] (three_two) {(2,T)};
        \node[state, minimum size=\minsz, below=of four] (four_one) {(1,T+1)};
        \node[state, minimum size=\minsz, below=of four_one] (four_two) {(2,T+1)};
        \node[draw=none, minimum size=\minsz, right=of four_one] (five_one) {};
        \node[draw=none, minimum size=\minsz, right=of four_two] (five_two) {};
        \node[draw=none, minimum size=\minsz, below=of three_two] (three_three) {};

        \draw[every loop]
            (two) edge node {\((T-1) \mu\)} (one)
            (three) edge node {\(T \mu\)} (two)
            (four) edge node {\((T+1) \mu\)} (three)
            (five) edge node {\((T+1) \mu\)} (four)
            (three_one) edge node {\(T \mu\)} (three)

            (four_one) edge node {\((T+1) \mu\)} (three_one)
            (five_one) edge node {\((T+1) \mu\)} (four_one)
            (three_two) edge node {\(T \mu\)} (three_one)
            (three_three) edge node {\(T \mu\)} (three_two)
            (four_two) edge node {\((T+1) \mu\)} (three_two)
            (five_two) edge node {\((T+1) \mu\)} (four_two)
            ;       
        
        \draw[->, red, ultra thick] (three_two) edge node {} (two);
        \draw[->, red, ultra thick] (three_one) edge node {} (two);
    \end{tikzpicture}
    \caption{Markov chain - ignoring any arrivals} 
    \label{other_patients_trip}
\end{figure}

As illustrated in figure \ref{other_patients_trip} a class 1 individual, 
when in the threshold column, only visits one of the nodes since they are not 
affected by class 2 individuals. 
Thus, one may acquire the desired time by calculating the inverse of the sum of 
the out-flow rate of that state. 
Since we are ignoring arrivals though the only way to exit the state will only be 
via a service. 
In essence this notion can be expressed as:

\begin{equation} \label{eq:sojourn_others}
    c^{(1)}(u,v) = 
    \begin{cases}
        0, & \textbf{if } u > 0 \textbf{ and } v = T \\
        \frac{1}{\text{min}(v,C)\mu}, & \textbf{otherwise}
    \end{cases}
\end{equation}

Note that whenever any class 1 individual is at a state \((u,v)\) where 
\(u > 0\) 
and \(v = T\) (i.e. all states \((1,T), (2,T) \dots, (M,T)\)) the sojourn time is 
set to \(0\). 
This is done to capture the trip thorough the Markov chain from the perspective 
of class 1 individuals. 
Meaning that they will visit all states of the threshold column but only the one 
in the first row will return a non-zero sojourn time.

Now, using the above equations, and considering all sates that belong in \(S_w\) 
the following recursive formula can be used to get the mean waiting time spent in 
each state in the Markov model. 
For class 1 individuals, whenever the model is at state \( (u,v) \), any 
incoming 
individual will proceed to arrive at state \( (u, v+1) \). 
individuals will then proceed to visit all other states until they reach one which 
has less than \(C\) servers occupied (i.e. until a server becomes available). 
The formula goes through all states from right to left recursively and adds the 
sojourn times of all these states together until it reaches a state that is not 
in the set of waiting states. 
Thus, the expected waiting time of a class 1 individual when they arrive at 
state \( (u,v) \) can be given by:

\begin{equation} \label{eq:waiting-time-at-each-state-other}
    w^{(1)}(u,v) = 
    \begin{cases} 
        0, \hspace{4.85cm} & \textbf{if } (u,v) \notin S_w \\
        c^{(1)}(u,v) + w^{(1)}(u-1, v), & \textbf{if } u > 0 \textbf{ and } v = T \\
        c^{(1)}(u,v) + w^{(1)}(u, v-1), & \textbf{otherwise}
    \end{cases}
\end{equation}

Finally, the mean waiting time can be calculated by summing over all expected 
waiting times of accepting states multiplied by the probability of being at that 
state and dividing by the probability of being in any accepting state.

\begin{equation} \label{eq:recursive-waiting-time-others}
    W^{(1)} = \frac{\sum_{(u,v) \in S_A^{(1)}} w^{(1)}(u,v) 
    \pi_{(u,v)}}{\sum_{(u,v) \in S_A^{(1)}} \pi_{(u,v)}}
\end{equation}



\subsubsection{Recursive formula for mean waiting time of 
class 2 individuals} \label{sec:recursive-waiting-time-ambulance}

Equivalently the mean waiting time for class 2 individuals can be calculated 
in a similar manner. 
The set of waiting states is the same as before but there is a slight modification 
in the set of accepting states.

\[
    S_w = \{(u, v) \in S \; | \; v > C \}    
\]

\begin{equation}\label{eq:accepting_states_class_2}
    S_A^{(2)}=
    \begin{cases}
        \{(u, v) \in S \; | \; u < M \} & \textbf{if } T \leq N\\
        \{(u, v) \in S \; | \; v < N \} & \textbf{otherwise}
    \end{cases}
\end{equation}

The set of accepting states is modified in such a way such that a class 2 
individual cannot arrive in the model when the model is at any state \((M, v)\) 
for 
all \(v \geq T\) where \(M\) is the buffer centre capacity and \(T\) is the threshold. 
An odd situation here is when the threshold is set to a very high number that is 
more than the actual system capacity. 
In such cases the set of accepting states is defined in the same way as the 
class 1 individuals case (\ref{eq:accepting_states_class_1}). 
That is because whenever \(T > N\) no class 2 individual will ever be blocked in 
the model 
(since that threshold can never be reached) and thus the last accepting state of 
the model will be state \( (0,N-1)\). 

Now just like in the class 1 individuals case the sojourn time is needed. 
For class 2 individuals whenever individuals are at any row apart from the 
first one they automatically get a wait time of \(0\) since they are essentially 
blocked.

\begin{equation} \label{eq:sojourn_ambulance}
    c^{(2)}(u,v) = 
    \begin{cases}
        0, & \textbf{if } u > 0 \\
        \frac{1}{\text{min}(v,C)\mu}, & \textbf{otherwise}
    \end{cases}
\end{equation}

Finally, the recursive formula and the mean waiting time equation are identical 
to the ones described above with the exception that they now use \(c^{(2)}(u,v)\) 
instead of \(c^{(1)}(u,v)\).
\begin{equation} \label{eq:waiting-time-at-each-state-ambulance}
    w^{(2)}(u,v) = 
    \begin{cases} 
        0, \hspace{4.85cm} & \textbf{if } (u,v) \notin S_w \\
        c^{(2)}(u,v) + w^{(2)}(u-1, v), & \textbf{if } u > 0 \textbf{ and } v = T \\
        c^{(2)}(u,v) + w^{(2)}(u, v-1), & \textbf{otherwise}
    \end{cases}
\end{equation}

\begin{equation}\label{eq:recursive-waiting-time-ambulance}
    W^{(2)} = \frac{\sum_{(u,v) \in S_A^{(2)}} w^{(2)}(u,v) \pi_{(u,v)}}
    {\sum_{(u,v) \in S_A^{(2)}} \pi_{(u,v)}}
\end{equation}


\subsubsection{Direct waiting time formula}
An alternative approach to getting the waiting time formula from the Markov
chain would be to simply solve the linear system of equations from equations
\ref{eq:waiting-time-at-each-state-other} and
\ref{eq:waiting-time-at-each-state-ambulance} for type 1 and type 2 individuals
respectively.
The set of equations that need to be solved for individuals of type \(i\) are
all \( w^{(i)}(u, v) \) for all possible states \((u,v) \in S\).

\begin{equation*}
    S_w = \{(u, v) \in S \; | \; v > C \}
\end{equation*}

\begin{equation*}
    S_A^{(1)} = \{(u, v) \in S \; | \; v < N \},
    \qquad
    S_A^{(2)}=
    \begin{cases}
        \{(u, v) \in S \; | \; u < M \} & \textbf{if } T \leq N \\
        \{(u, v) \in S \; | \; v < N \} & \textbf{otherwise}
    \end{cases}
\end{equation*}


\begin{equation*}
    c^{(1)}(u,v) = 
    \begin{cases}
        0, & \textbf{if } u > 0 \textbf{ and } v = T \\
        \frac{1}{\min(v,C) \mu}, & \textbf{otherwise}
    \end{cases}
    \qquad
    c^{(2)}(u,v) = 
    \begin{cases}
        0, & \textbf{if } u > 0 \\
        \frac{1}{\text{min}(v,C)\mu}, & \textbf{otherwise}
    \end{cases}
\end{equation*}


\begin{equation}
    w^{(i)}(u,v) = 
    \begin{cases} 
        0, & \textbf{if } (u,v) \notin S_b \\
        c^{(i)}(u,v) + w^{(i)}(u - 1, v), & \textbf{if } u > 0 
        \textbf{ and } v = T\\
        c^{(i)}(u,v) + w^{(i)}(u, v-1), & \textbf{otherwise } \\
    \end{cases}
\end{equation}


\begin{multicols*}{2}
    \begin{figure}[H]
        \centering
        \scalebox{0.60}{\input{MarkovChain/expressions_from_pi/example_model_2231/main.tex}}
        \caption{Example of Markov chain}
        \label{fig:example-algeb-waiting}
    \end{figure}
    \columnbreak
    \begin{align}
        w^{(i)}(1,2) &= c(1,2) + w^{(i)}(0,2) \label{eq:first_eq_of_waiting_example} \\
        w^{(i)}(1,3) &= c(1,3) + w^{(i)}(1,2) \\
        % w^{(i)}(1,4) &= c(1,4) + w^{(i)}(1,3) \\
        w^{(i)}(2,2) &= c(2,2) + w^{(i)}(1,2) \\
        w^{(i)}(2,3) &= c(2,3) + w^{(i)}(2,2) \label{eq:last_eq_of_waiting_example}
        % w^{(i)}(2,4) &= c(2,4) + w^{(i)}(2,3) 
    \end{align}
\end{multicols*}



Thus similar to equations \ref{eq:recursive-waiting-time-others} and
\ref{eq:recursive-waiting-time-ambulance} the mean waiting time for type \(i\)
individuals is given by:

\begin{equation}
    W^{(i)} = \frac{\sum_{(u,v) \in S_A^{(i)}} \pi_{(u,v)} w^{(i)}
    (\mathcal{A}_i(u,v))}{\sum_{(u,v) \in S_A^{(i)}} \pi_{(u,v)}}
\end{equation}


Here \(S_A^{(2)}\) is the set of accepting states of type 2 individuals and 
\(\mathcal{A}_i(u,v)\) for \(i \in \{1, 2\} \) is the state that the system
would go to when the system is at state \( (u,v) \) and an individual of type
\(i\) arrives. 

\begin{equation}\label{eq:arriving_state_class_1}
    \mathcal{A}_1(u,v) = (u, v + 1)
\end{equation}
\begin{equation}\label{eq:arriving_state_class_2}
    \mathcal{A}_2(u,v) = 
    \begin{cases}
        (u, v + 1), & \text{if } v < T \\
        (u + 1, v), & \text{if } v \geq T \\
    \end{cases}
\end{equation}


\subsubsection{Mean Waiting Time - Closed-form}
Upon closer inspection of the recursive formula a more compact formula can arise. 
The equivalent closed-form formula eliminates the need for recursion and thus makes 
the computation of waiting times much more efficient. 
Just like in the recursive part there are two formulas; one for \textit{class 1} 
and one for class 2 individuals. 
The formulas are given by:

\begin{equation} \label{eq:closed_form_waiting_others}
    W^{(1)} = \frac{\sum_{\substack{(u,v) \, \in S_A^{(1)} \\ v \geq C}} 
    \frac{1}{C \mu} \times (v-C+1) \times \pi(u,v)}{\sum_{(u,v) \, 
    \in S_A^{(1)}} \pi(u,v)}
\end{equation}
    
\begin{equation}\label{eq:closed_form_waiting_ambulance}
    W^{(2)} = \frac{\sum_{\substack{(u,v) \, \in S_A^{(2)} \\ min(v,T) \geq C}} 
    \frac{1}{C \mu} \times (\min(v+1,T)-C) \times \pi(u,v)}{\sum_{(u,v) \, 
    \in S_A^{(2)}} \pi(u,v)}
\end{equation}

Note here that the summation, in both equations \ref{eq:closed_form_waiting_others} 
and \ref{eq:closed_form_waiting_ambulance}, goes through all states in the set of 
accepting 
states of either class 1 or class 2 individuals respectively, where a wait 
incurs. 
In equation \ref{eq:closed_form_waiting_others} that includes all states \((u,v)\) 
in the set of accepting states of class 1 individuals such that \( v \geq C\); i.e. 
whenever an arrival occurs and the system is at a state where the number of individuals 
in the system is more than or equal to $C$. 
Consequently, for the states that are included in the summation the expression 
\( v-C+1 \) indicates the amount of people in service one would have to wait for 
upon arrival at the hospital.

Additionally, the minimisation function in equation 
\ref{eq:closed_form_waiting_ambulance} 
ensures that when a class 2 individual arrives at any state 
that is greater than the predetermined threshold, the wait that the individual will 
have to endure remains the same. 
In essence, the expression \(\min(v+1,T) - C\) returns the number of people in line 
in front of a particular individual upon arrival.


\subsubsection{Overall Waiting Time}

Consequently, the overall waiting time should can be estimated by a linear combination 
of the waiting times of class 1 and class 2 individuals. 
The overall waiting time can be then given by the following equation where \(c_1\) 
and \(c_2\) are the coefficients of each individual's type waiting time:

\begin{equation}\label{eq:overall_waiting_time_coeff}
    W = c_1 W^{(1)} + c_2 W^{(2)}
\end{equation}

The two coefficients represent the proportion of individuals of each type that 
traversed through the model. 
Theoretically, getting these percentages should be as simple as looking at the arrival 
rates of each type but in practise if the service centre or the buffer centre 
is full, some individuals may be lost to the system. 
Thus, one should account for the probability that an individual is lost to the system. 
This probability can be easily calculated by using the two sets of accepting states 
\(S_A^{(2)}\) and \(S_A^{(1)}\) defined earlier in equations 
\ref{eq:accepting_states_class_1} 
and \ref{eq:accepting_states_class_2}. 
Let us define here the probability, for either class type, that an individual 
is not lost in the system by:

\begin{equation*}
    P(L'_1) = \sum_{(u,v) \, \in S_A^{(1)}} \pi(u,v) \hspace{2cm}
    P(L'_2) = \sum_{(u,v) \, \in S_A^{(2)}} \pi(u,v)
\end{equation*}

Having defined these probabilities one may combine them with the arrival rates of 
each class type in such a way to get the expected proportions of class 1 and 
class 2 individuals in the model. 
Thus, by using these values as the coefficient of equation 
\ref{eq:overall_waiting_time_coeff} 
the resultant equation can be used to get the overall waiting time. 
Note here that the equation below gets the overall waiting time for both the recursive 
and the closed-form formula.

\begin{equation}\label{eq:overall_waiting_time}
    W = \frac{\lambda_1 P(L'_1)}{\lambda_2 P(L'_2) + \lambda_1 P(L'_1)} W^{(1)} + 
    \frac{\lambda_2 P(L'_2)}{\lambda_2 P(L'_2) + \lambda_1 P(L'_1)} W^{(2)}
\end{equation}



\subsection{Mean blocking time}

\subsubsection{Direct approach for mean blocking time}

Unlike the waiting time, the blocking time is only calculated for class 2 individuals.  
That is because class 1 individuals cannot be blocked. 
Thus, one only needs to consider the pathway of class 2 individuals to get the 
mean blocking time of the system. 
Blocking occurs at states \((u,v)\) where \(u > 0 \). 
Thus, the set of blocking states can be defined as:

\begin{equation*}
    S_b = \{(u,v) \in S \; | \; u > 0\}
\end{equation*}
 
In order to not consider individuals that will be lost to the system, the set of 
accepting states needs to be taken into account. As defined in section 
\ref{sec:recursive-waiting-time-ambulance},
the set of accepting states is given by (\ref{eq:accepting_states_class_2}):

\begin{equation*}
    S_A^{(2)}=
    \begin{cases}
        \{(u, v) \in S \; | \; u < M \} & \textbf{if } T \leq N\\
        \{(u, v) \in S \; | \; v < N \} & \textbf{otherwise}
    \end{cases}
\end{equation*}

For the waiting time formula in sections \ref{sec:recursive-waiting-time-others}
and \ref{sec:recursive-waiting-time-ambulance}
the mean sojourn time for each state was considered,
ignoring any arrivals. Here, the same approach is used but ignoring only class 2
arrivals. That is because for the waiting time formula, once an individual enters 
the service centre (i.e. starts waiting) any individual arriving after them will 
not affect their
pathway. That is not the case for blocking time. When a class 2 individual is 
blocked, 
any class 1 individual that arrives will cause the blocked individual to remain 
blocked for more time. Therefore, class 1 arrivals are considered here:

\begin{equation}\label{eq:time_in_state_blocking_time}
    c(u,v) = 
    \begin{cases}
        \frac{1}{\min(v,C) \mu}, & \text{if } v = C\\
        \frac{1}{\min(v,C) \mu + \lambda_1}, & \text{otherwise}
    \end{cases}
\end{equation}
 
In equation \ref{eq:time_in_state_blocking_time}, both service completions and 
class 1 arrivals are considered. 
Thus, from a blocked individual's perspective whenever the system moves from one 
state \((u,v)\)
to another state it can either:

\begin{itemize}
    \item be because of a service being completed: we will denote the probability 
    of this happening by \(p_s(u,v)\). 
    \item be because of an arrival of an individual of class 1: denoting such 
    probability by \(p_o(u,v)\).
\end{itemize}
The probabilities are given by:

\begin{equation*}
    p_s(u,v) = \frac{\min(v,C)\mu}{\lambda_1 + \min(v,C)\mu}, \qquad
    p_o(u,v) = \frac{\lambda_1}{\lambda_1 + \min(v,C)\mu}
\end{equation*}


Having defined \(c(u,v)\) and \(S_b\) a formula for the blocking time that is
expected to occur at each state can be given by:

\begin{equation}\label{eq:blocking-time-at-each-state}
    b(u,v) = 
    \begin{cases} 
        0, & \textbf{if } (u,v) \notin S_b \\
        c(u,v) + b(u - 1, v), & \textbf{if } v = N = T\\
        c(u,v) + b(u, v-1), & \textbf{if } v = N \neq T \\
        c(u,v) + p_s(u,v) b(u-1, v) + p_o(u,v) b(u, v+1), & \textbf{if } u > 0 
        \textbf{ and } v = T \\
        c(u,v) + p_s(u,v) b(u, v-1) + p_o(u,v) b(u, v+1), & \textbf{otherwise} \\
    \end{cases}
\end{equation}

Unlike equations (\ref{eq:waiting-time-at-each-state-other}) and 
(\ref{eq:waiting-time-at-each-state-ambulance}), equation 
(\ref{eq:blocking-time-at-each-state}) will not be solved recursively. 
A direct approach will be used to solve this equation here. 
By enumerating all equations of (\ref{eq:blocking-time-at-each-state}) for all 
states \((u,v)\) that belong in \(S_b\) 
a system of linear equations arises where the unknown variables are all the \(b(u,v)\)
terms.
For instance, let us consider a Markov model where \(C=2, T=3, N=6, M=2\). 
The Markov model is shown in Figure \ref{fig:example-algeb-blocking}
and the equivalent equations are 
(\ref{eq:first_eq_of_blocking_example})-(\ref{eq:last_eq_of_blocking_example}).
The equations considered here are only the ones that correspond to the blocking 
states.

\begin{multicols*}{2}
    \begin{figure}[H]
        \scalebox{0.50}{\input{MarkovChain/expressions_from_pi/example_model_2242/main.tex}}
        \caption{Example of Markov chain}
        \label{fig:example-algeb-blocking}
    \end{figure}
    \columnbreak
    \begin{align}
        b(1,2) &= c(1,2) + p_o b(1,3) \label{eq:first_eq_of_blocking_example} \\
        b(1,3) &= c(1,3) + p_s b(1,2) + p_o b(1,4) \\
        b(1,4) &= c(1,4) + b(1,3) \\
        b(2,2) &= c(2,2) + p_s b(1,2) + p_o b(2,3) \\
        b(2,3) &= c(2,3) + p_s b(2,2) + p_o b(1,4) \\
        b(2,4) &= c(2,4) + b(2,3)\label{eq:last_eq_of_blocking_example}
    \end{align}
\end{multicols*}

Additionally, the above equations can be transformed into a linear system of the 
form \(Zx=y\) where:

\begin{equation}\label{eq:example-algebaric-approach-blocking-time}
    Z=
    \begin{pmatrix}
        -1 & p_o & 0 & 0 & 0 & 0 \\ %(1,2)
        p_s & -1 & p_o & 0 & 0 & 0 \\ %(1,3)
        0 & 1 & -1 & 0 & 0 & 0 \\ %(1,4)
        p_s & 0 & 0 & -1 & p_o & 0\\ %(2,2)
        0 & 0 & 0 & p_s & -1 & p_o \\ %(2,3)
        0 & 0 & 0 & 0 & 1 & -1 \\ %(2,4)
    \end{pmatrix},
    x=
    \begin{pmatrix}
        b(1,2) \\
        b(1,3) \\
        b(1,4) \\
        b(2,2) \\
        b(2,3) \\
        b(2,4) \\
    \end{pmatrix}, 
    y=
    \begin{pmatrix}
        -c(1,2) \\
        -c(1,3) \\
        -c(1,4) \\
        -c(2,2) \\
        -c(2,3) \\
        -c(2,4) \\
    \end{pmatrix}
\end{equation}

A more generalised form of the equations in 
(\ref{eq:example-algebaric-approach-blocking-time})
can thus be given for any value of \(C,T,N,M\) by:

\begin{align}
    b(1,T) =& c(1, T) + p_o b(1, T + 1) \label{eq:first_eq_of_blocking_general}\\
    b(1,T + 1) =& c(1, T + 1) + p_s(1, T) + p_o b(1, T + 1) \\
    b(1,T + 2) =& c(1, T + 2) + p_s(1, T + 1) + p_o b(1, T + 3) \\
    & \vdots \nonumber \\
    b(1, N) =& c(1, N) + b(1, N - 1) \\
    b(2, T) =& c(2, T) + p_s b(1, T) + p_o b(2, T + 1) \\
    b(2, T + 1) =& c(2, T + 1) + p_s b(2, T) + p_o b(2, T + 2) \\
    & \vdots \nonumber \\
    b(M, T) =& c(M, T) + b(M, T-1) \label{eq:last_eq_of_blocking_general}
\end{align}

The equivalent matrix form of the linear system of equations 
(\ref{eq:first_eq_of_blocking_general}) - (\ref{eq:last_eq_of_blocking_general})
is given by \(Zx=y\), where:
\begin{equation}\label{eq:general-algebaric-approach-blocking-time}
    \scalebox{0.9}{
        \(
        Z = 
        \begin{pmatrix}
            -1 & p_o & 0 & \dots & 0 & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ %(1,T)
            p_s & -1 & p_o & \dots & 0 & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ %(1,T+1)
            0 & p_s & -1 & \dots & 0 & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ %(1,T+2)
            \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \vdots & 
            \vdots & \ddots & \vdots & \vdots \\ 
            0 & 0 & 0 & \dots & 1 & -1 & 0 & 0 & 0 & \dots & 0 & 0 \\ %(1,N)
            p_s & 0 & 0 & \dots & 0 & 0 & -1 & p_o & 0 & \dots & 0 & 0 \\ %(2,T)
            0 & 0 & 0 & \dots & 0 & 0 & p_s & -1 & p_o & \dots & 0 & 0 \\ %(2,T+1)
            \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \vdots & 
            \vdots & \ddots & \vdots & \vdots \\ 
            0 & 0 & 0 & \dots & 0 & 0 & 0 & 0 & 0 & \dots & 1 & -1 \\ %(M,T)
        \end{pmatrix},
        x = 
        \begin{pmatrix}
            b(1,T) \\
            b(1,T+1) \\
            b(1,T+2) \\
            \vdots \\
            b(1,N) \\
            b(2,T) \\
            b(2,T+1) \\
            \vdots \\
            b(M,T) \\
        \end{pmatrix}, 
        y= 
        \begin{pmatrix}
            -c(1,T) \\
            -c(1,T+1) \\
            -c(1,T+2) \\
            \vdots \\
            -c(1,N) \\
            -c(2,T) \\
            -c(2,T+1) \\
            \vdots \\
            -c(M,T) \\
        \end{pmatrix}
        \)
    }
\end{equation}

Thus, having calculated the mean blocking time for all blocking states \(b(u,v)\), 
it only remains to put them together in a formula just like in equations 
\ref{eq:recursive-waiting-time-others} and \ref{eq:recursive-waiting-time-ambulance}.
The resultant blocking time formula is given by:

\begin{equation}\label{eq:algebraic-blocking-time}
    B = \frac{\sum_{(u,v) \in S_A} \pi_{(u,v)} \; b(u,v)}{\sum_{(u,v) \in S_A} 
    \pi_{(u,v)}}
\end{equation}


\subsection{Mean proportion of arrivals within time target}

Another performance measure that needs to be taken into consideration is the 
proportion of individuals whose waiting and service times lie within a specified 
time target.
In order to consider such measure though one would need to obtain the 
distribution of time in the system for all individuals. The complexity of such 
a task lies on the fact that different individuals arrive at different states of
the Markov model. Let us first consider the case when an arrival occurs when the
model is at a specific state.

\subsubsection{Distribution of time at a specific state (with 1 server)}

\begin{figure}[h]
    \centering
    \scalebox{0.75}{\input{MarkovChain/expressions_from_pi/example_model_1242/main.tex}}
    \caption{Example Markov model \(C=1, T=2, N=4, M=2\)}
    \label{fig:distribution-of-time-at-specific-state-1-server}
\end{figure}

Consider the Markov model of figure 
\ref{fig:distribution-of-time-at-specific-state-1-server} with one server and a 
threshold of two individuals. 
Let us now assume that a class 1 individual arrives when the model is at state 
\((0,3)\), thus forcing the model to move to state \((0,4)\). 
The distribution of the time needed for the specified individual to exit the 
system from state \((0,4)\) is given by the sum of exponentially distributed 
random variables with the same parameter \(\mu\). 
The sum of such random variables form the Erlang distribution which is defined 
by the number of random variables that are added and their exponential 
parameter.
Note here that these random variables represent the individual's pathway from 
the perspective of the individual. 
Thus, \(X_i\) represents the random variable of the time that it takes for an
individual to move from the \(i^{\text{th}}\) position of the queue to the 
\((i-1)^{\text{th}}\) position (i.e. for someone in front of them to finish 
their service) and \(X_0\) is the time it takes that individual to move from 
having a service to exiting the system.


\begin{align}
    (0,4) \Rightarrow \quad & X_3 \sim Exp(\mu) \nonumber \\
    (0,3) \Rightarrow \quad & X_2 \sim Exp(\mu) \nonumber \\
    (0,2) \Rightarrow \quad & X_1 \sim Exp(\mu) \nonumber \\
    (0,1) \Rightarrow \quad & X_0 \sim Exp(\mu) \nonumber \\
    S = X_3 + X_2 + & X_1 + X_0 = Erlang(4, \mu)
\end{align}

Thus, the waiting and service time of an individual in the model of figure 
\ref{fig:distribution-of-time-at-specific-state-1-server} can be captured by an 
erlang distributed random variable. 
The general CDF of the erlang distribution \(Erlang(k, \mu)\) is given by:

\begin{equation} \label{eq:cdf-erlang}
    P(S < t) = 1 - \sum_{i=0}^{k-1} \frac{1}{i!} e^{-\mu t} (\mu t)^i
\end{equation}

Unfortunately, the erlang distribution can only be used for the sum of 
identically distributed random variables from the exponential distribution. 
Therefore, this approach cannot be used when one of the random variables has a 
different parameter than the others. 
In fact the only case where we can use it is only when the number of servers are
\(C=1\), just like in the explored example, or when an individual arrives and 
goes straight to service (i.e. when there is no other individual waiting and 
there is an empty server).


\subsubsection{Distribution of time at a specific state (with multiple servers)}

\begin{figure}[h]
    \centering
    \scalebox{0.75}{\input{MarkovChain/expressions_from_pi/example_model_2242/main.tex}}
    \caption{Example Markov model \(C=2, T=2, N=4, M=2\)}
    \label{fig:distribution-of-time-at-specific-state-2-servers}
\end{figure}

Figure \ref{fig:distribution-of-time-at-specific-state-2-servers} represents the 
same Markov model as figure 
\ref{fig:distribution-of-time-at-specific-state-1-server} with the only 
exception that there are 2 servers here. 
By applying the same logic, assuming that an individual arrives at state 
\((0,4)\), the sum of the following random variables arises.

\begin{align}
    (0,4) \Rightarrow \quad & X_2 \sim Exp(2\mu) \nonumber \\
    (0,3) \Rightarrow \quad & X_1 \sim Exp(2\mu) \\
    (0,2) \Rightarrow \quad & X_0 \sim Exp(\mu) \nonumber
\end{align}

Since these exponentially distributed random variables do not share the same 
parameter, an erlang distribution cannot be used. 
In fact, the problem can now be viewed either as the sum of exponentially 
distributed random variables with different parameters or as the sum of 
erlang distributed random variables.
The sum of erlang distributed random variables is said to follow the 
hypoexponential distribution. 
The hypoexponential distribution is defined with two vectors of size equal
to the number of Erlang random variables that are added together
\cite{Akkouchi2008}, \cite{Smaili2013}. 
For this particular example:

\begin{align} \label{eq:multiple-servers-distribution-example}
    \begin{rcases}
        \begin{rcases}
            X_2 \sim Exp(2\mu) \\
            X_1 \sim Exp(2\mu)
        \end{rcases}
        X_1 + X_2 = S_1 \sim Erlang(2, 2\mu) \\
        X_0 \sim Exp(\mu) \Rightarrow \hspace{1cm} X_0 = S_2 \sim Erlang(1, \mu)
    \end{rcases}
    S_1 + S_2 = H \sim Hypo((2,1), (2\mu, \mu)) 
\end{align}

The random variable \(H\) from equation 
\ref{eq:multiple-servers-distribution-example} follows a hypoexponential 
distribution with two vector parameters. 
The CDF of this distribution can be therefore used to get the probability of the 
time in spent in the system being less than a given target.
The CDF of the general hypoexponential distribution \(Hypo(\vec{r}, 
\vec{\lambda})\), is given by the following expression, where vector \(\vec{r}\) 
contains all \(k\)-values of the erlang distributions and \(\vec{\lambda}\) 
is a vector of the distinct parameters \cite{Favaro2010}.

\begin{align} \label{eq:general-cdf-hypoexponential}
    & P(H < t) = 1 - \left( \prod_{j=1}^{\mid \vec{r} \mid} \lambda_j^{r_j} \right) 
    \sum_{k=1}^{\mid \vec{r} \mid} \sum_{l=1}^{r_k} \frac{\Psi_{k,l}(-\lambda_k)t^{r_k - l} 
    e^{-\lambda_k t}}
    {(r_k - l)! (l - 1)!} \nonumber \\ 
    & \textbf{where} \qquad \Psi_{k,l}(t) = - \frac{\partial^{l - 1}}
    {\partial t ^{l - 1}} \left( \prod_{j = 0, j \neq k}^{\mid \vec{r} \mid} 
    (\lambda_j + t)^{-r_j} \right) \nonumber \\
    & \textbf{and} \quad \qquad \lambda_0 = 0, r_0 = 1
\end{align}


The computation of the derivative makes equation \ref{eq:general-cdf-hypoexponential}
computationally expensive. 
In \cite{Legros2015} an alternative linear version of that CDF is explored via 
matrix analysis, and is given by the following formula:

\begin{equation} \label{eq:linear-general-cdf-hypoexponential}
    \begin{split}
        F(x) = &1 - \sum_{k=1}^{n} \sum_{l=0}^{k-1} (-1)^{k-1} \binom{n}{k} 
            \binom{k-1}{l} \sum_{j=1}^{n} \sum_{s=1}^{j-1} e^{-x \lambda_s} 
            \prod_{l=1}^{s-1} \left( \frac{\lambda_l}{\lambda_l - \lambda_s} \right)
            ^ {k_s} \\
        & \times \sum_{s < a_1 < \dots < a_{l-1} < j} 
            \left( \frac{\lambda_s}{\lambda_s - \lambda_{a_1}} \right) ^ {k_s}
            \prod_{m=s+1}^{a_1-1} \left( \frac{\lambda_m}{\lambda_m - 
            \lambda_{a_1}}\right) ^ {k_m}  
            \prod_{n=a_1}^{a_2-1} \left( \frac{\lambda_n}{\lambda_n - 
            \lambda_{a_2}}\right) ^ {k_n} \\
        & \dots \prod_{r=a_l-1}^{j-1} \left( \frac{\lambda_r}{\lambda_r - 
            \lambda_{a_j}}\right) ^ {k_r}  
            \sum_{q=0}^{k_s - 1} \frac{((\lambda_s - \lambda_{a_1})x)^q}{q!}, \\
        & \text{for } \geq 0
    \end{split}
\end{equation}


\subsubsection{Specific CDF of hypoexponential distribution}
Equations \ref{eq:general-cdf-hypoexponential} and 
\ref{eq:linear-general-cdf-hypoexponential} refers to the general CDF of the
hypoexponential distribution where the size of the vector parameters can be of
any size \cite{Favaro2010}.
In the Markov chain models described in figures 
\ref{fig:distribution-of-time-at-specific-state-1-server} and 
\ref{fig:distribution-of-time-at-specific-state-2-servers} the parameter vectors 
of the hypoexponential distribution are of size two, and in fact, for any 
possible version of the investigated Markov chain model the vectors can only be 
of size two.
This is true since for any dimensions of this Markov chain model there will 
always be at most two distinct exponential parameters; the parameter for 
finishing a service (\(\mu\)) and the parameter for moving forward in the queue 
(\(C \mu\)). 
For the special case of \(C=1\) the hypoexponential distribution will not be 
used as this is equivalent to an erlang distribution.
Therefore, by fixing the sizes of \(\vec{r}\) and \(\vec{\lambda}\) to 2, the 
following specific expression for the CDF of the hypoexponential distribution
arises, where the derivative is removed:


\begin{align} \label{eq:specific-cdf-hypoexponential}
    & P(H < t) = 1 - \left( \prod_{j=1}^{\mid \vec{r} \mid} \lambda_j^{r_j} \right) 
    \sum_{k=1}^{\mid \vec{r} \mid} \sum_{l=1}^{r_k} \frac{\Psi_{k,l}(-\lambda_k)t^{r_k - l} 
    e^{-\lambda_k t}}{(r_k - l)! (l - 1)!} \nonumber \\ 
    & \textbf{where} \qquad \Psi_{k,l}(t) = 
    \begin{cases} 
        \frac{(-1)^{l} (l-1)!}{\lambda_2} \left[\frac{1}{t^l} - \frac{1}
        {(t + \lambda_2)^l}\right] , & k=1 \\
        - \frac{1}{t (t + \lambda_1)^{r_1}}, & k=2
    \end{cases} \nonumber \\
    & \textbf{and} \quad \qquad \lambda_0 = 0, r_0 = 1
\end{align}

Note here that the only difference between equation 
\ref{eq:general-cdf-hypoexponential} and \ref{eq:specific-cdf-hypoexponential} 
is the \(\Psi\) function. The next section proves why the following expression 
is true:

\begin{equation} \label{eq:hypoexponential-expression-to-proof}
    - \frac{\partial^{l - 1}}{\partial t ^{l - 1}} 
    \left( \prod_{j = 0, j \neq k}^{\mid \vec{r} \mid} (\lambda_j + t)^{-r_j} \right) = 
    \begin{cases} 
        \frac{(-1)^{l} (l-1)!}{\lambda_2} \left[\frac{1}{t^l} - \frac{1}
        {(t + \lambda_2)^l}\right] , & k=1 \\
        - \frac{1}{t (t + \lambda_1)^{r_1}}, & k=2
    \end{cases}
\end{equation}



\subsubsection{Proof of specific hypoexponential distribution 
\ref{eq:hypoexponential-expression-to-proof}}
 
This section aims to show that there exists a simplified expression of equation 
\ref{eq:general-cdf-hypoexponential} that is specific to the proposed Markov 
model.
Function \(\Psi\) is defined using the parameter \(t\) and the variables \(k\) 
and \(l\).
Given the Markov model, the range of values that \(k\) and \(l\) can take can be
bounded.
First of all, from the range of the double summation in equation 
\ref{eq:general-cdf-hypoexponential}, it can be seen that 
\(k = 1, 2, \dots, \mid \vec{r} \mid\).
Now, \(\mid \vec{r} \mid\) represents the size of the parameter vectors that, 
for the Markov model, will always be 2. 
That is because, for all the exponentially distributed random variables that are
added together to form the new distribution, there only two distinct parameters,
thus forming two erlang distributions. Therefore:

\begin{equation*}
    k = 1, 2
\end{equation*}

By observing equation \ref{eq:general-cdf-hypoexponential} once more, the range
of values that \(l\) takes are \(l = 1, 2, \dots, r_k\), where \(r_1\) is 
subject to the individual's position in the queue and \(r_2 = 1\).
In essence, the hypoexponential distribution will be used with these bounds:

\begin{align}
    k = 1 & \qquad \Rightarrow \qquad l = 1, 2, \dots, r_1 \nonumber \\
    k = 2 & \qquad \Rightarrow \qquad l = 1
\end{align}

Thus the left hand side of equation \ref{eq:hypoexponential-expression-to-proof} 
needs only to be defined for these bounds. 
The specific hypoexponential distribution investigated here is of the form
\(Hypo((r_1, 1)(\lambda_1, \lambda_2))\).
Note the initial conditions \(\lambda_0=0, r_0=1\) defined in equation 
\ref{eq:general-cdf-hypoexponential} also hold here.
Thus the proof is split into two parts, for \(k=1\) and \(k=2\).



\begin{itemize}
    \item \(k = 2, l = 1\)
    \begin{equation*}
        \begin{split}
            LHS &= - \frac{\partial^{1-1}}{\partial t^{1-1}} 
            \left( \prod_{j=0, j \neq 2}^{2} (\lambda_j + t)^{-r_j} \right) \\
            &=-\left( (\lambda_0 + t)^{-r_0} \times (\lambda_1 + t)^{-r_1} \right) \\
            &=-\left( t^{-1} \times (\lambda_1 + t)^{-r_1} \right) \\ 
            &= - \frac{1}{t(t + \lambda_1)^{r_1}} \\
            & \hspace{7cm} \square
        \end{split}
    \end{equation*}
    \item \(k = 1, l = 1, \dots, r_1\)
    \begin{equation*}
        \begin{split}
            LHS &= -\frac{\partial^{l-1}}{\partial t^{l-1}} 
            \left( \prod_{j=0, j \neq 1}^{2} (\lambda_j + t)^{-r_j} \right) \\
            &= -\frac{\partial^{l-1}}{\partial t^{l-1}}
            \left( (\lambda_o + t)^{-r_0} \times (\lambda_2 + t)^{-r_2} \right) \\
            &= -\frac{\partial^{l-1}}{\partial t^{l-1}}
            \left( \frac{1}{t(t + \lambda_2)}\right)
        \end{split}
    \end{equation*}
    In essence, it only remains to show that 
    \(-\frac{\partial^{l-1}}{\partial t^{l-1}} 
    \left( \frac{1}{t(t + \lambda_2)}\right) = \frac{(-1)^{l} (l-1)!}{\lambda_2}
    \left[\frac{1}{t^l} - \frac{1}{(t + \lambda_2)^l}\right]\).
    
    \textbf{Proof by Induction:}
    \begin{enumerate}
        \item Base case (\(l=1\)):
        \begin{equation*}
            \begin{split}
                LHS &= -\frac{\partial^{1-1}}{\partial t^{1-1}} 
                \left( \frac{1}{t(t + \lambda_2)}\right) = 
                - \frac{1}{t(t + \lambda_2)} \\
                RHS &= \frac{(-1)^{1} (1-1)!}{\lambda_2}
                \left[\frac{1}{t^1} - \frac{1}{(t + \lambda_2)^1}\right] \\
                &= - \frac{t + \lambda_2 - t}{\lambda_2 t (t + \lambda_2)} \\
                &= - \frac{1}{t (t + \lambda_2)} \\
                LHS &= RHS
            \end{split}
        \end{equation*}
        \item Assume true for \(l = x\):
        \begin{equation*}
            -\frac{\partial^{x-1}}{\partial t^{x-1}} 
            \left( \frac{1}{t(t + \lambda_2)}\right) = 
            \frac{(-1)^{x} (x-1)!}{\lambda_2}
            \left[\frac{1}{t^x} - \frac{1}{(t + \lambda_2)^x}\right]
        \end{equation*}
        \item Prove true for \(l = x + 1\): 
        \(\Bigg( \frac{\partial^x}{\partial t ^ x} 
        \left( \frac{-1}{t (t + \lambda_2)} \right) = 
        \frac{(-1)^{x + 1} (x)!}{\lambda_2}
        \left[\frac{1}{t^{x+1}}-\frac{1}{(t + \lambda_2)^{x+1}}\right] \Bigg)\)
        \begin{equation*}
            \begin{split}
                LHS &= \frac{\partial}{\partial t}
                \left[ \frac{\partial^{x-1}}{\partial t ^ {x-1}} 
                \left( \frac{-1}{t (t + \lambda_2)} \right) \right] \\
                &= \frac{\partial}{\partial t} \left[
                    \frac{(-1)^x (x-1)!}{\lambda_2} \left(
                        \frac{1}{t^x} - \frac{1}{(t + \lambda_2)^x}
                    \right)
                \right] \\
                &= \frac{(-1)^x (x-1)!}{\lambda_2} \left(
                    \frac{(-x)}{t^{x+1}} - \frac{(-x)}{(t + \lambda_2)^x}
                \right) \\
                &= \frac{(-1)^x (x-1)! (-x)}{\lambda_2} \left(
                    \frac{1}{t^{x+1}} - \frac{1}{(t + \lambda_2)^x}
                \right) \\
                &= \frac{(-1)^{x+1} (x)!}{\lambda_2} \left(
                    \frac{1}{t^{x+1}} - \frac{1}{(t + \lambda_2)^x}
                \right) \\
                & = RHS \\
                & \hspace{7cm} \square
            \end{split}
        \end{equation*}
    \end{enumerate}
\end{itemize}

\subsubsection{Proportion within target for class 1 and class 2 individuals}

Given the two CDFs of the Erlang and Hypoexponential distributions a new 
function has to be defined to decide which one to use among the two.
Based on the state of the model, there can be three scenarios when an individual
arrives.
\begin{enumerate}
    \item There is a free server and the individual does not have to wait
    \begin{equation*}
        X_{(u,v)} \sim Erlang(1, \mu) 
    \end{equation*}
    \item The individual arrives at a queue at the \(n^{th}\) position and the 
    model has \(C > 1\) servers
    \begin{equation*}
        X_{(u,v)} \sim Hypo((n, 1), (C \mu, \mu)) 
    \end{equation*}
    \item The individual arrives at a queue at the \(n^{th}\) position and the 
    model has \(C = 1\) servers
    \begin{equation*}
        X_{(u,v)} \sim Erlang(n + 1, \mu) 
    \end{equation*}
\end{enumerate}

Note here that for the first case \(Erlang(1, \mu)\) is equivalent to 
\(Exp(\mu)\). 
Let us define \(X_{(u,v)}^{(1)}\) the distribution of class 1 individuals and
\(X_{(u,v)}^{(2)}\) the distribution of class 2 individuals, when arriving at 
state \((u,v)\) of the model.

\begin{equation}
    X_{(u,v)}^{(1)} \sim 
    \begin{cases}
        \textbf{Erlang}(v, \mu), & \textbf{if } C = 1 \textbf{ and } v>1 \\
        \textbf{Hypo}\left(\vec{r}=(v - C, 1), \vec{\lambda}=(C \mu, \mu)\right), 
            & \textbf{if } C > 1 \textbf{ and } v>C \\
        \textbf{Erlang}(1, \mu), & \textbf{if } v \leq C
    \end{cases}
\end{equation}

\begin{equation}
    X_{(u,v)}^{(2)} \sim 
    \begin{cases}
        \textbf{Erlang}(\min(v, T), \mu), & \textbf{if } C = 1
            \textbf{ and } v, T > 1 \\
        \textbf{Hypo}\left(\vec{r}=(\min(v, T) - C, 1), \vec{\lambda}=(C \mu, \mu)\right), & 
            \textbf{if } C > 1 \textbf{ and } v, T  > C \\
        \textbf{Erlang}(1, \mu), & \textbf{if } v \leq C \textbf{ or } T \leq C
    \end{cases}
\end{equation}


Equations \ref{eq:cdf-erlang} and \ref{eq:specific-cdf-hypoexponential} can now
be used.
Therefore, the probability that an individual arriving at a specific state is 
within a given time target \(t\) is given by the following formulas:


\begin{equation}
    P(X_{(u,v)}^{(1)} < t) = 
    \begin{cases}
        1 - \sum_{i=0}^{v-1} \frac{1}{i!} e^{-\mu t} (\mu t)^i, 
            & \textbf{if } C = 1 \textbf{ and } v>1 \\
        & \\
        1 - (\mu C)^{v-C} \mu  
            \sum_{k=1}^{\mid \vec{r} \mid} \sum_{l=1}^{r_k}
            \frac{\Psi_{k,l}(-\lambda_k)t^{r_k - l} 
            e^{-\lambda_k t}}{(r_k - l)! (l - 1)!},
            & \textbf{if } C > 1 \textbf{ and } v > C \\
        \textbf{where } \vec{r}=(v - C, 1) \textbf{ and } 
            \vec{\lambda}=(C \mu, \mu) & \\
        & \\
        1 - e^{-\mu t},  & \textbf{if } v \leq C
    \end{cases}
\end{equation}


\begin{equation}
    P(X_{(u,v)}^{(2)} < t) = 
    \begin{cases}
        1 - \sum_{i=0}^{\min(v,T)-1} \frac{1}{i!} e^{-\mu t} (\mu t)^i,  
            & \textbf{if } C = 1 \textbf{ and } v, T > 1 \\
        & \\
        1 - (C \mu ) ^ {\min(v,T) - C} \mu
            \sum_{k=1}^{\mid \vec{r} \mid} \sum_{l=1}^{r_k}
            \frac{\Psi_{k,l}(-\lambda_k)t^{r_k - l} 
            e^{-\lambda_k t}}{(r_k - l)! (l - 1)!}, 
            & \textbf{if } C > 1 \textbf{ and } v, T  > C \\
        \textbf{where } \vec{r}=(\min(v, T) - C, 1) \textbf{ and } 
            \vec{\lambda}=(C \mu, \mu) & \\
        & \\
        1 - e^{-\mu t}, & \textbf{if } v \leq C \textbf{ or } T \leq C
    \end{cases}
\end{equation}


In addition the set of accepting states for class 1 (\(S_A^{(1)}\)) and class 2 
(\(S_A^{(2)}\)) individuals defined in  (\ref{eq:accepting_states_class_1}) and 
(\ref{eq:accepting_states_class_2}) are also needed here.
Note here that, \(S\) denotes the set of all states of the Markov chain model. 

\begin{align*}
    S_A^{(1)} &= \{(u, v) \in S \; | \; v < N \} \\
    S_A^{(2)} &=
    \begin{cases}
        \{(u, v) \in S \; | \; u < M \}, & \textbf{if } T \leq N \\
        \{(u, v) \in S \; | \; v < N \}, & \textbf{otherwise}
    \end{cases}
\end{align*}

Having defined everything, it only remains to use a formula similar to the ones 
of equations \ref{eq:recursive-waiting-time-others}, 
\ref{eq:recursive-waiting-time-ambulance} and 
\ref{eq:general-algebaric-approach-blocking-time}.
The following formula uses the state probability vector \(\pi\) to get the 
weighted average of the probability below target of all states in the Markov
model.

\begin{equation}
    P(X^{(1)} < t) = \frac{\sum_{(u,v) \in S_A^{(1)}} P(X_{u,v}^{(1)} < t) 
    \pi_{u,v} }{\sum_{(u,v) \in S_A^{(1)}} \pi_{u,v}}
\end{equation}

\begin{equation}
    P(X^{(2)} < t) = \frac{\sum_{(u,v) \in S_A^{(2)}} P(X_{u,v}^{(2)} < t) 
    \pi_{u,v} }{\sum_{(u,v) \in S_A^{(2)}} \pi_{u,v}}
\end{equation}


\subsubsection{Overall proportion within target}

The overall proportion of individuals for both class 1 and class 2 individuals
is given by the equivalent formula of equations 
(\ref{eq:overall_waiting_time_coeff}) and (\ref{eq:overall_waiting_time}).
The following formula uses the probability of lost individuals from both classes
to get the weighted sum of the two already existing probabilities.

\begin{equation*}
    P(L'_1) = \sum_{(u,v) \, \in S_A^{(1)}} \pi(u,v), \hspace{1.5cm}
    P(L'_2) = \sum_{(u,v) \, \in S_A^{(2)}} \pi(u,v)
\end{equation*}

\begin{equation}\label{eq:overall_proportion_within_target}
    P(X < t)= \frac{\lambda_1 P(L'_1)}{\lambda_2 P(L'_2)+\lambda_1 P(L'_1)} 
    P(X^{(1)} < t) + \frac{\lambda_2 P(L'_2)}{\lambda_2 P(L'_2) + \lambda_1 
    P(L'_1)} P(X^{(2)} < t)
\end{equation}


